{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LoadedModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1erRvDS3VmGxqYiEAHWZMyhdJ38ZbW4Pv",
      "authorship_tag": "ABX9TyNsTg6SK3ePwtde7E4nZukW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Um-e-Hani/DevOps-R-Repo1111/blob/main/Code/LoadedModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nya9aNbwBHKH"
      },
      "outputs": [],
      "source": [
        "#convert output category value to tag\n",
        "def logits_to_tokens(output, index, test_sent):\n",
        "  token_sequences = []\n",
        "  token_num = len(test_sent)\n",
        "  count = 0\n",
        "  for categorical_sequence in output:\n",
        "    token_sequence = []\n",
        "    for categorical in categorical_sequence:\n",
        "      token_sequence.append(tagList[np.argmax(categorical)-1])\n",
        "      count = count + 1\n",
        "      if(token_num == count):\n",
        "        break\n",
        "    token_sequences.append(token_sequence)\n",
        "  return token_sequences\n",
        "\n",
        "#function to prepare a sentence to allow model POS prediction\n",
        "def getSentence_x(sentence, word2index):\n",
        "  sentence_index = []\n",
        "  for word in sentence:\n",
        "      try:\n",
        "          sentence_index.append(word2index[word])\n",
        "      except KeyError:\n",
        "          sentence_index.append(word2index['-OOV-'])\n",
        "  return sentence_index\n",
        "\n",
        "#predict function output\n",
        "def predictFunct(test_sentence, sentOriginal):\n",
        "  l1 = []\n",
        "  l1.append(test_sentence.tolist())\n",
        "  output = model.predict(l1)\n",
        "\n",
        "  #converting output to readable form\n",
        "  p_tags = logits_to_tokens(output, tagList, sentOriginal)\n",
        "  return p_tags"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load json module\n",
        "import json\n",
        "\n",
        "#reading word2Index\n",
        "with open(\"/content/drive/MyDrive/FYP/POS-Tagging-Urdu/files/word2index\") as f:\n",
        "  word2index = json.loads(f.read())\n",
        "\n",
        "#reading tagList\n",
        "with open(\"/content/drive/MyDrive/FYP/POS-Tagging-Urdu/files/tagList\") as fp:\n",
        "  tagList = json.loads(fp.read())\n"
      ],
      "metadata": {
        "id": "D5fOl8N1CaFT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Keras\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential, Model, load_model, save_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, InputLayer, Masking, TimeDistributed, LSTM, Conv1D, Embedding\n",
        "from tensorflow.keras.layers import GRU, Bidirectional, BatchNormalization, Reshape\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.keras.layers import Reshape, Dropout, Dense,Multiply, Dot, Concatenate,Embedding\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "#reconstructing model\n",
        "model = keras.models.load_model(\"/content/drive/MyDrive/FYP/POS-Tagging-Urdu/models/1/mlp.h5\")\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaoMrKD9Cqzr",
        "outputId": "1fc6e0ed-5676-44ad-b8a6-313a5a1ec4ef"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 281, 128)          5332736   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 281, 128)          16512     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 281, 41)           5289      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 281, 41)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,354,537\n",
            "Trainable params: 5,354,537\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask-ngrok\n",
        "!pip install pydub\n",
        "!pip install SpeechRecognition\n",
        "!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg\n",
        "!pip install pyaudio\n",
        "!pip install gevent\n",
        "!pip install ngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0omhM1p8feSG",
        "outputId": "a234a127-a19f-43f6-c932-bdb6bf7f173f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.7/dist-packages (0.0.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.4)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask-ngrok) (2.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.7/dist-packages (0.25.1)\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.7/dist-packages (3.8.1)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libportaudio2 is already the newest version (19.6.0-1).\n",
            "libportaudiocpp0 is already the newest version (19.6.0-1).\n",
            "portaudio19-dev is already the newest version (19.6.0-1).\n",
            "libasound2-dev is already the newest version (1.1.3-5ubuntu0.6).\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "Requirement already satisfied: pyaudio in /usr/local/lib/python3.7/dist-packages (0.2.11)\n",
            "Collecting gevent\n",
            "  Downloading gevent-21.12.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 21.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: greenlet<2.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from gevent) (1.1.2)\n",
            "Collecting zope.interface\n",
            "  Downloading zope.interface-5.4.0-cp37-cp37m-manylinux2010_x86_64.whl (251 kB)\n",
            "\u001b[K     |████████████████████████████████| 251 kB 55.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from gevent) (57.4.0)\n",
            "Collecting zope.event\n",
            "  Downloading zope.event-4.5.0-py2.py3-none-any.whl (6.8 kB)\n",
            "Installing collected packages: zope.interface, zope.event, gevent\n",
            "Successfully installed gevent-21.12.0 zope.event-4.5.0 zope.interface-5.4.0\n",
            "Requirement already satisfied: ngrok in /usr/local/lib/python3.7/dist-packages (0.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#python flask application\n",
        "from flask import Flask,request,jsonify\n",
        "from flask_ngrok  import run_with_ngrok\n",
        "\n",
        "#import library\n",
        "import speech_recognition as sr\n",
        "import numpy as np\n",
        "\n",
        "# Initialize recognizer class (for recognizing the speech)\n",
        "r = sr.Recognizer()\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/upload', methods=['GET', 'POST'])\n",
        "def hello_world():\n",
        "  if request.method == 'POST':\n",
        "    f = request.files['file']\n",
        "    #sound = AudioSegment.from_mp3(f)\n",
        "    #sound.export(f, format=\"wav\")\n",
        "    filePath = \"./audio.wav\"\n",
        "    f.save(filePath)\n",
        "    \n",
        "    # Reading Audio file as source\n",
        "    # listening the audio file and store in audio_text variable\n",
        "    with sr.AudioFile('audio.wav') as source:\n",
        "      audio_text = r.listen(source)\n",
        "        \n",
        "    # recoginize_() method will throw a request error if the API is unreachable, hence using exception handling\n",
        "    try:   \n",
        "        # using google speech recognition\n",
        "        sentence = r.recognize_google(audio_text, language = \"ur-PK\")\n",
        "        print('Converting audio transcripts into text ...')\n",
        "        print(sentence)\n",
        "    except:\n",
        "         print('Sorry.. run again...')\n",
        "\n",
        "    #getting tags for sentence\n",
        "    sentOriginal = np.array(sentence.split(\" \"))\n",
        "    sent = np.array(getSentence_x(sentOriginal, word2index))\n",
        "\n",
        "    #converting output to readable form\n",
        "    val = 281 - int(sent.shape[0])\n",
        "    new = np.pad(sent, (0, val), 'constant')\n",
        "    p_tags = predictFunct(new, sentOriginal)\n",
        "\n",
        "    #creating return string\n",
        "    retStr = \"\"\n",
        "    for x in range(0,len(p_tags[0])):\n",
        "      retStr = retStr + sentOriginal[x] + \"|\" + p_tags[0][x] + \" \"\n",
        "    print(retStr)\n",
        "\n",
        "    return jsonify({\n",
        "\t\t\"message\": retStr\n",
        "\t  })\n",
        "\n",
        "run_with_ngrok(app)\n",
        "#if __name__ == \"__main__\":\n",
        "app.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h67FFqE9ZFrj",
        "outputId": "65a772b4-bea9-4224-93f0-65dec947220c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting audio transcripts into text ...\n",
            "وہ دسویں جماعت میں پڑھتا ہے\n",
            "['وہ' 'دسویں' 'جماعت' 'میں' 'پڑھتا' 'ہے']\n",
            "[['PP', 'OR', 'NN', 'P', 'VB', 'TA']]\n",
            "وہ|PP دسویں|OR جماعت|NN میں|P پڑھتا|VB ہے|TA \n"
          ]
        }
      ]
    }
  ]
}